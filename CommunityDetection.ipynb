{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.dataset.entities import Entities\n",
    "from modules.dataset.tweets import Tweets\n",
    "from modules.network import HashNet\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEETS_DB_PATH = 'data/db/tweets.json'  # Path to tweets dataset\n",
    "HASHTAGS_DB_PATH = 'data/db/hashtags.json' # Path to hashtags dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define networks container, indexed by periods\n",
    "networks = {\n",
    "    2017: None,\n",
    "    2018: None,\n",
    "    2019: None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>836950901495631872</td>\n",
       "      <td>2017-03-01 14:46:59</td>\n",
       "      <td>TT SINGAPORE 22:46\\n1.Hong Kong\\n2.#JointAddre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>836950882528989184</td>\n",
       "      <td>2017-03-01 14:46:54</td>\n",
       "      <td>Letting #snapchat prepare me for the day's uns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>836950869639835649</td>\n",
       "      <td>2017-03-01 14:46:51</td>\n",
       "      <td>\"The bill would require the state to get all o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>836950847380668416</td>\n",
       "      <td>2017-03-01 14:46:46</td>\n",
       "      <td>Style-Lead don't Follow #recycledfashion https...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>836950839101116421</td>\n",
       "      <td>2017-03-01 14:46:44</td>\n",
       "      <td>‘Shell knew’: oil giant's 1991 film warned of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id          tweet_date  \\\n",
       "0  836950901495631872 2017-03-01 14:46:59   \n",
       "1  836950882528989184 2017-03-01 14:46:54   \n",
       "2  836950869639835649 2017-03-01 14:46:51   \n",
       "3  836950847380668416 2017-03-01 14:46:46   \n",
       "4  836950839101116421 2017-03-01 14:46:44   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  TT SINGAPORE 22:46\\n1.Hong Kong\\n2.#JointAddre...  \n",
       "1  Letting #snapchat prepare me for the day's uns...  \n",
       "2  \"The bill would require the state to get all o...  \n",
       "3  Style-Lead don't Follow #recycledfashion https...  \n",
       "4  ‘Shell knew’: oil giant's 1991 film warned of ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import tweets dataset\n",
    "tweets = Tweets()\n",
    "tweets.from_json(TWEETS_DB_PATH)\n",
    "tweets.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>entity_index</th>\n",
       "      <th>entity_text</th>\n",
       "      <th>entity_tag</th>\n",
       "      <th>entity_conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1101574442575167489</td>\n",
       "      <td>0</td>\n",
       "      <td>#Humans</td>\n",
       "      <td>#</td>\n",
       "      <td>0.6243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1101574442575167489</td>\n",
       "      <td>7</td>\n",
       "      <td>#climatechange</td>\n",
       "      <td>^</td>\n",
       "      <td>0.4925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1101574446341607424</td>\n",
       "      <td>27</td>\n",
       "      <td>#ClimateChange</td>\n",
       "      <td>#</td>\n",
       "      <td>0.6968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1101574446341607424</td>\n",
       "      <td>36</td>\n",
       "      <td>#ActOnClimate</td>\n",
       "      <td>#</td>\n",
       "      <td>0.7929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1101574446341607424</td>\n",
       "      <td>37</td>\n",
       "      <td>#climate</td>\n",
       "      <td>#</td>\n",
       "      <td>0.9559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id  entity_index     entity_text entity_tag  entity_conf\n",
       "0  1101574442575167489             0         #Humans          #       0.6243\n",
       "1  1101574442575167489             7  #climatechange          ^       0.4925\n",
       "2  1101574446341607424            27  #ClimateChange          #       0.6968\n",
       "3  1101574446341607424            36   #ActOnClimate          #       0.7929\n",
       "4  1101574446341607424            37        #climate          #       0.9559"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags = Entities()\n",
    "hashtags.from_json(HASHTAGS_DB_PATH)\n",
    "hashtags.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of hashtags used as search seeds\n",
    "seed_list = [\"#climatechange\", \"#climate\", \"#sdgs\", \"#sustainability\", \"#environment\", \"#globalwarming\"]\n",
    "\n",
    "for period in networks.keys():\n",
    "    # Subset tweets for current period\n",
    "    curr_tweets = Tweets()\n",
    "    curr_tweets.df = tweets.df.loc[tweets.df.tweet_date.dt.year == period].copy()\n",
    "    # Get ids of tweets for current period\n",
    "    curr_tweets_id = curr_tweets.df.tweet_id.unique()\n",
    "    # Subset hashtags and words associated to current tweets\n",
    "    curr_hashtags = Entities()\n",
    "    curr_hashtags.df = hashtags.df.loc[hashtags.df.tweet_id.isin(curr_tweets_id)].copy()\n",
    "    # Lower hashtags\n",
    "    curr_hashtags.df[\"entity_text\"] = curr_hashtags.df[\"entity_text\"].str.lower()\n",
    "    # Remove seeds from hashtag dataset\n",
    "    curr_hashtags.df = curr_hashtags.df.loc[~curr_hashtags.df.entity_text.isin(seed_list)]\n",
    "    #curr_words.df = curr_words.df.loc[~curr_words.df.entity_text.isin(seed_list)]\n",
    "    # Generate a dictionary containing words and hashtags networks for each period\n",
    "    networks[period] = HashNet.from_entities(curr_hashtags)\n",
    "    \n",
    "    del curr_hashtags, curr_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 hashtags network consists in 218 connected components\n",
      "The largest cc corresponds to 77% of total\n",
      "2018 hashtags network consists in 206 connected components\n",
      "The largest cc corresponds to 86% of total\n",
      "2019 hashtags network consists in 185 connected components\n",
      "The largest cc corresponds to 88% of total\n"
     ]
    }
   ],
   "source": [
    "for period in networks.keys():\n",
    "    net_type = \"hashtags\"\n",
    "    # Get the list of connected components sorted by size\n",
    "    cc = networks[period].get_connected_components()\n",
    "    # If there is only one cc\n",
    "    if len(cc) == 1:\n",
    "        print(\"{} {} network is connected\".format(period, net_type))\n",
    "    else:\n",
    "        # Compute the ratio between the size of the largest cc and the sum of all the cc sizes\n",
    "        gc_ratio = int(100*cc[0][\"size\"]/sum([cc[i][\"size\"] for i in range(len(cc))]))\n",
    "        # Print results\n",
    "        print(\"{} {} network consists in {} connected components\".format(period, net_type, len(cc)))\n",
    "        print(\"The largest cc corresponds to {}% of total\".format(gc_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the largest connected components\n",
    "for period in networks.keys():\n",
    "    # Get the largest connected component\n",
    "    lcc = networks[period].get_connected_components()[0][\"component\"]\n",
    "    # Project the network on the lcc\n",
    "    networks[period] = networks[period].project_component(lcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCommunitiesLouvain(network, resolution=1.0, threshold = 100):\n",
    "    \"\"\"\n",
    "    Filter communities with less than threshold hashtags\n",
    "    return: \n",
    "        comm: map community_id -> list of hashtags\n",
    "        partitions: map hashtag -> community_id\n",
    "    \"\"\" \n",
    "    # compute best partitions (fixed random state for reproducibility)\n",
    "    partition = community.best_partition(graph=network, weight='weight', resolution=resolution, random_state=100)\n",
    "    size = float(len(set(partition.values())))\n",
    "    print('There are {} communities'.format(size))\n",
    "    \n",
    "    # partition is a dictionary in the form {'hashtag':community_id, ...}\n",
    "    # we want ot transform it in the form {'community_id':[hashtag1, hashtag2, ...]}\n",
    "    communities = {}\n",
    "    for p in partition:\n",
    "        if partition[p] in communities:\n",
    "            communities[partition[p]].append(p)\n",
    "        else:\n",
    "            communities[partition[p]] = [p]\n",
    "\n",
    "    # delete small communities (size(community)<threshold)\n",
    "    communities = {k:v for k, v in communities.items() if len(v)>threshold}\n",
    "    print('-> {} communities remaining after filtering'.format(len(communities)))\n",
    "    return communities, partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Year: 2017 ---\n",
      "There are 33.0 communities\n",
      "-> 13 communities remaining after filtering\n",
      "\n",
      "--- Year: 2018 ---\n",
      "There are 35.0 communities\n",
      "-> 20 communities remaining after filtering\n",
      "\n",
      "--- Year: 2019 ---\n",
      "There are 35.0 communities\n",
      "-> 18 communities remaining after filtering\n",
      "\n"
     ]
    }
   ],
   "source": [
    "communities = {\n",
    "    2017: None,\n",
    "    2018: None,\n",
    "    2019: None\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    2017: {'resolution':0.9, 'threshold':70},\n",
    "    2018: {'resolution':0.9, 'threshold':100},\n",
    "    2019: {'resolution':0.9, 'threshold':100},\n",
    "}\n",
    "\n",
    "for period in networks.keys():\n",
    "    print(\"--- Year: {} ---\".format(period))\n",
    "    comm, partitions = getCommunitiesLouvain(\n",
    "        networks[period].net,\n",
    "        resolution=parameters[period]['resolution'],\n",
    "        threshold=parameters[period]['threshold']\n",
    "    )\n",
    "    communities[period] = {\n",
    "        'communities': comm,\n",
    "        'partitions': partitions\n",
    "    }\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(d, descending=True):\n",
    "    \"\"\"\n",
    "    Sort a dictionary based on items\n",
    "    \"\"\"\n",
    "    return {k: v for k, v in sorted(d.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "def printCommunitiElemnts(\n",
    "    network, communities, num_communities=5,\n",
    "    community_id=None, metric_name='centrality',\n",
    "    showTopK=5, print_metric=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Print most important nodes based on certain metric\n",
    "    \"\"\"\n",
    "    if metric_name=='centrality':\n",
    "        centrality = nx.degree_centrality(network)\n",
    "        metric = centrality\n",
    "        \n",
    "    if metric_name=='degree':\n",
    "        degree = nx.degree(network, weight='weight')\n",
    "        metric = degree\n",
    "        \n",
    "    # find most relevant (based on metric) terms for each community\n",
    "    if community_id == None:\n",
    "        counter = 1\n",
    "        for k,v in communities.items():\n",
    "            print('---Community: {}, Size: {}---'.format(k, len(v)))\n",
    "            tag_dict = {tag: metric[tag] for tag in v}\n",
    "            tag_dict = sort_dict(tag_dict)\n",
    "            tag_list = list(tag_dict.keys())\n",
    "            for tag in tag_list[:showTopK]:\n",
    "                if print_metric:\n",
    "                    print(tag, ',{}: {:.4f}'.format(metric_name, metric[tag]))\n",
    "                else:\n",
    "                    print(tag)\n",
    "            print()\n",
    "            ## Show only num_communities\n",
    "            if counter == num_communities:\n",
    "                break\n",
    "            counter += 1\n",
    "    else:\n",
    "        k = community_id\n",
    "        if k not in communities:\n",
    "            print(\"Community {} has been discarded (too small)\".format(k))\n",
    "            return\n",
    "        v = communities[community_id]\n",
    "        print('---Community: {}---'.format(k))\n",
    "        tag_dict = {tag: metric[tag] for tag in v}\n",
    "        tag_dict = sort_dict(tag_dict)\n",
    "        tag_list = list(tag_dict.keys())\n",
    "        for tag in tag_list[:showTopK]:\n",
    "            if print_metric:\n",
    "                print(tag, ',{}: {:.4f}'.format(metric_name, metric[tag]))\n",
    "            else:\n",
    "                print(tag)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Community: 0, Size: 182---\n",
      "#un\n",
      "#sustainabledevelopment\n",
      "#peace\n",
      "#sdg\n",
      "#nigeria\n",
      "#unitednations\n",
      "#2030agenda\n",
      "\n",
      "---Community: 1, Size: 350---\n",
      "#climateaction\n",
      "#fridaysforfuture\n",
      "#climatecrisis\n",
      "#extinctionrebellion\n",
      "#climateactionnow\n",
      "#climateemergency\n",
      "#schoolstrike4climate\n",
      "\n",
      "---Community: 2, Size: 269---\n",
      "#nature\n",
      "#pollution\n",
      "#conservation\n",
      "#usa\n",
      "#savetheplanet\n",
      "#india\n",
      "#trees\n",
      "\n",
      "---Community: 3, Size: 313---\n",
      "#innovation\n",
      "#ai\n",
      "#iot\n",
      "#news\n",
      "#circulareconomy\n",
      "#plastic\n",
      "#plasticfree\n",
      "\n",
      "---Community: 4, Size: 269---\n",
      "#energy\n",
      "#climatestrike\n",
      "#greennewdeal\n",
      "#renewables\n",
      "#solar\n",
      "#renewableenergy\n",
      "#actonclimate\n",
      "\n",
      "---Community: 7, Size: 150---\n",
      "#agriculture\n",
      "#research\n",
      "#environmental\n",
      "#deforestation\n",
      "#food\n",
      "#farmers\n",
      "#foodsecurity\n",
      "\n",
      "---Community: 8, Size: 145---\n",
      "#africa\n",
      "#love\n",
      "#art\n",
      "#development\n",
      "#tourism\n",
      "#music\n",
      "#cycloneidai\n",
      "\n",
      "---Community: 9, Size: 157---\n",
      "#green\n",
      "#arctic\n",
      "#zerowaste\n",
      "#earthday\n",
      "#adventure\n",
      "#indigenous\n",
      "#animals\n",
      "\n",
      "---Community: 10, Size: 145---\n",
      "#science\n",
      "#climatechangeisreal\n",
      "#resist\n",
      "#scicomm\n",
      "#gender\n",
      "#migration\n",
      "#fracking\n",
      "\n",
      "---Community: 11, Size: 242---\n",
      "#auspol\n",
      "#co2\n",
      "#biodiversity\n",
      "#coal\n",
      "#oil\n",
      "#csr\n",
      "#ausvotes2019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "year = 2019\n",
    "\n",
    "printCommunitiElemnts(\n",
    "    networks[year].net, communities[year]['communities'],\n",
    "    num_communities=10, metric_name='centrality',\n",
    "    print_metric=False, showTopK=7, community_id=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Community: 0, Size: 156---\n",
      "#weather\n",
      "#iot\n",
      "#engineering\n",
      "#smartcities\n",
      "#jobs\n",
      "#people\n",
      "#efficiency\n",
      "\n",
      "---Community: 1, Size: 212---\n",
      "#globalgoals\n",
      "#design\n",
      "#architecture\n",
      "#construction\n",
      "#landscape\n",
      "#organic\n",
      "#building\n",
      "\n",
      "---Community: 2, Size: 333---\n",
      "#energy\n",
      "#solar\n",
      "#renewables\n",
      "#climateaction\n",
      "#renewableenergy\n",
      "#africa\n",
      "#cdnpoli\n",
      "\n",
      "---Community: 3, Size: 315---\n",
      "#nature\n",
      "#wildlife\n",
      "#animals\n",
      "#oceans\n",
      "#photography\n",
      "#spring\n",
      "#forest\n",
      "\n",
      "---Community: 4, Size: 156---\n",
      "#parisagreement\n",
      "#auspol\n",
      "#climatechangeisreal\n",
      "#earthday\n",
      "#theresistance\n",
      "#coal\n",
      "#qldpol\n",
      "\n",
      "---Community: 7, Size: 210---\n",
      "#csr\n",
      "#youth\n",
      "#climatejustice\n",
      "#esg\n",
      "#cop24\n",
      "#social\n",
      "#sdg5\n",
      "\n",
      "---Community: 8, Size: 238---\n",
      "#sustainable\n",
      "#waste\n",
      "#business\n",
      "#reuse\n",
      "#environmental\n",
      "#recycling\n",
      "#startup\n",
      "\n",
      "---Community: 9, Size: 123---\n",
      "#women\n",
      "#iwd2018\n",
      "#gender\n",
      "#tshirt\n",
      "#reading\n",
      "#nzpol\n",
      "#unitednations\n",
      "\n",
      "---Community: 10, Size: 238---\n",
      "#innovation\n",
      "#science\n",
      "#education\n",
      "#technology\n",
      "#ecology\n",
      "#development\n",
      "#economy\n",
      "\n",
      "---Community: 11, Size: 276---\n",
      "#water\n",
      "#agriculture\n",
      "#food\n",
      "#worldwaterday\n",
      "#biodiversity\n",
      "#data\n",
      "#foodsecurity\n",
      "\n"
     ]
    }
   ],
   "source": [
    "year = 2018\n",
    "\n",
    "printCommunitiElemnts(\n",
    "    networks[year].net, communities[year]['communities'],\n",
    "    num_communities=10, metric_name='centrality',\n",
    "    print_metric=False, showTopK=7, community_id=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Community: 0, Size: 136---\n",
      "#globalgoals\n",
      "#education\n",
      "#iwd2017\n",
      "#agenda2030\n",
      "#logic\n",
      "#womensday\n",
      "#beboldforchange\n",
      "\n",
      "---Community: 3, Size: 135---\n",
      "#resist\n",
      "#humanrights\n",
      "#theresistance\n",
      "#maga\n",
      "#women\n",
      "#usa\n",
      "#republicans\n",
      "\n",
      "---Community: 4, Size: 78---\n",
      "#science\n",
      "#auspol\n",
      "#arctic\n",
      "#jobs\n",
      "#qldpol\n",
      "#sciencemarch\n",
      "#syria\n",
      "\n",
      "---Community: 5, Size: 148---\n",
      "#energy\n",
      "#cdnpoli\n",
      "#renewables\n",
      "#solar\n",
      "#renewableenergy\n",
      "#waterislife\n",
      "#actonclimate\n",
      "\n",
      "---Community: 6, Size: 84---\n",
      "#recycle\n",
      "#ecofriendly\n",
      "#sustainabledevelopment\n",
      "#foodwaste\n",
      "#waste\n",
      "#change\n",
      "#zerohunger\n",
      "\n",
      "---Community: 11, Size: 91---\n",
      "#nature\n",
      "#wildlife\n",
      "#conservation\n",
      "#biodiversity\n",
      "#art\n",
      "#disaster\n",
      "#colombia\n",
      "\n",
      "---Community: 12, Size: 90---\n",
      "#trump\n",
      "#epa\n",
      "#coal\n",
      "#gogreen\n",
      "#earthday\n",
      "#china\n",
      "#earthhour2017\n",
      "\n",
      "---Community: 16, Size: 85---\n",
      "#health\n",
      "#pollution\n",
      "#airquality\n",
      "#wellness\n",
      "#airpollution\n",
      "#cleanair\n",
      "#healthyliving\n",
      "\n",
      "---Community: 17, Size: 115---\n",
      "#sustainable\n",
      "#water\n",
      "#earth\n",
      "#food\n",
      "#agriculture\n",
      "#eco\n",
      "#love\n",
      "\n",
      "---Community: 18, Size: 84---\n",
      "#innovation\n",
      "#csr\n",
      "#business\n",
      "#impinv\n",
      "#energyefficiency\n",
      "#esg\n",
      "#corpgov\n",
      "\n"
     ]
    }
   ],
   "source": [
    "year = 2017\n",
    "\n",
    "printCommunitiElemnts(\n",
    "    networks[year].net, communities[year]['communities'],\n",
    "    num_communities=10, metric_name='centrality',\n",
    "    print_metric=False, showTopK=7, community_id=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Community: 1---\n",
      "#climateaction\n",
      "#fridaysforfuture\n",
      "#climatecrisis\n",
      "#extinctionrebellion\n",
      "#climateactionnow\n",
      "#climateemergency\n",
      "#schoolstrike4climate\n",
      "#gretathunberg\n",
      "#genderequality\n",
      "#iwd2019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inspect community by id\n",
    "year = 2019\n",
    "\n",
    "printCommunitiElemnts(\n",
    "    networks[year].net, communities[year]['communities'],\n",
    "    num_communities=10, metric_name='centrality',\n",
    "    print_metric=False, showTopK=10, community_id=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
